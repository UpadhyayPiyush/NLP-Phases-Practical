{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bRAPQ8Q8eVFo"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "from nltk.tokenize import sent_tokenize as st\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer,SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_W7Aeynep_A",
    "outputId": "18de24ea-cb68-4ec6-b666-7b488d90ae5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics. It is primarily concerned with giving computers the ability to support and manipulate human language. It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic (i.e. statistical and, most recently, neural network-based) machine learning approaches. The goal is a computer capable of understanding the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves. Challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation. Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules. Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing. This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing. Creating a single sentence with 50 lines can be quite challenging due to its length and complexity, but I can provide you with a lengthy sentence that attempts to cover a variety of topics and ideas:  It is quite a common requirement for users to remove certain characters from their text files while displaying. This is done to assure that only displayable characters are displayed or data should be displayed in a specific structure. This article will teach you how to read a text file into a string variable and strip newlines using Python. The task could be performed using the replace function, a default function in all Python distributions. Where old is the string to be replaced and new is the string that will replace it. Firstly the path to the file is defined. Then the fileâ€™s contents are read and stored in the variable named data. All the occurrences of the newline character in the variable data are replaced with the empty string (nothing). In the end, the data after stripping the newlines are displayed. The task could also be performed using the split function, a default function in all Python distributions. The function takes in an argument (optional) a character (or string) and splits the string based on the occurrence of that character in it. Firstly the file is read and stored in a variable as before. Then the variable is passed through the split function, which splits the string and creates a list based on the occurrences of the passed argument. In this case, it was the newline character. Thus after this process, we ended up with a list containing substrings of the original strings. The Splitlines is a function that splits/breaks a string based on the occurrence of escape sequences. The function converts the string to a list upon stripping the control characters. Hence, all the list elements must be iterated to get the final string. This method is almost identical to the split method described earlier. The only difference is that the split lines function does not require any argument and is made to work only with line boundaries. Hence, the splitting of data would be made on any occurrence of a line boundary.      \n"
     ]
    }
   ],
   "source": [
    "with open('corpus.txt','r') as file:\n",
    "    sent1 = \" \".join(line.rstrip() for line in file)\n",
    "print(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckAQp4b0fJed",
    "outputId": "46566200-2df8-4487-a08d-3e2e73ac6cfb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zqvtlhn1fRri",
    "outputId": "2e699270-641c-492c-c8b0-08ac47f493ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'an', 'interdisciplinary', 'subfield', 'of', 'computer', 'science', 'and', 'linguistics', '.', 'It', 'is', 'primarily', 'concerned', 'with', 'giving', 'computers', 'the', 'ability', 'to', 'support', 'and', 'manipulate', 'human', 'language', '.', 'It', 'involves', 'processing', 'natural', 'language', 'datasets', ',', 'such', 'as', 'text', 'corpora', 'or', 'speech', 'corpora', ',', 'using', 'either', 'rule-based', 'or', 'probabilistic', '(', 'i.e', '.', 'statistical', 'and', ',', 'most', 'recently', ',', 'neural', 'network-based', ')', 'machine', 'learning', 'approaches', '.', 'The', 'goal', 'is', 'a', 'computer', 'capable', 'of', 'understanding', 'the', 'contents', 'of', 'documents', ',', 'including', 'the', 'contextual', 'nuances', 'of', 'the', 'language', 'within', 'them', '.', 'The', 'technology', 'can', 'then', 'accurately', 'extract', 'information', 'and', 'insights', 'contained', 'in', 'the', 'documents', 'as', 'well', 'as', 'categorize', 'and', 'organize', 'the', 'documents', 'themselves', '.', 'Challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'speech', 'recognition', ',', 'natural-language', 'understanding', ',', 'and', 'natural-language', 'generation', '.', 'Up', 'to', 'the', '1980s', ',', 'most', 'natural', 'language', 'processing', 'systems', 'were', 'based', 'on', 'complex', 'sets', 'of', 'hand-written', 'rules', '.', 'Starting', 'in', 'the', 'late', '1980s', ',', 'however', ',', 'there', 'was', 'a', 'revolution', 'in', 'natural', 'language', 'processing', 'with', 'the', 'introduction', 'of', 'machine', 'learning', 'algorithms', 'for', 'language', 'processing', '.', 'This', 'was', 'due', 'to', 'both', 'the', 'steady', 'increase', 'in', 'computational', 'power', '(', 'see', 'Moore', \"'s\", 'law', ')', 'and', 'the', 'gradual', 'lessening', 'of', 'the', 'dominance', 'of', 'Chomskyan', 'theories', 'of', 'linguistics', '(', 'e.g', '.', 'transformational', 'grammar', ')', ',', 'whose', 'theoretical', 'underpinnings', 'discouraged', 'the', 'sort', 'of', 'corpus', 'linguistics', 'that', 'underlies', 'the', 'machine-learning', 'approach', 'to', 'language', 'processing', '.', 'Creating', 'a', 'single', 'sentence', 'with', '50', 'lines', 'can', 'be', 'quite', 'challenging', 'due', 'to', 'its', 'length', 'and', 'complexity', ',', 'but', 'I', 'can', 'provide', 'you', 'with', 'a', 'lengthy', 'sentence', 'that', 'attempts', 'to', 'cover', 'a', 'variety', 'of', 'topics', 'and', 'ideas', ':', 'It', 'is', 'quite', 'a', 'common', 'requirement', 'for', 'users', 'to', 'remove', 'certain', 'characters', 'from', 'their', 'text', 'files', 'while', 'displaying', '.', 'This', 'is', 'done', 'to', 'assure', 'that', 'only', 'displayable', 'characters', 'are', 'displayed', 'or', 'data', 'should', 'be', 'displayed', 'in', 'a', 'specific', 'structure', '.', 'This', 'article', 'will', 'teach', 'you', 'how', 'to', 'read', 'a', 'text', 'file', 'into', 'a', 'string', 'variable', 'and', 'strip', 'newlines', 'using', 'Python', '.', 'The', 'task', 'could', 'be', 'performed', 'using', 'the', 'replace', 'function', ',', 'a', 'default', 'function', 'in', 'all', 'Python', 'distributions', '.', 'Where', 'old', 'is', 'the', 'string', 'to', 'be', 'replaced', 'and', 'new', 'is', 'the', 'string', 'that', 'will', 'replace', 'it', '.', 'Firstly', 'the', 'path', 'to', 'the', 'file', 'is', 'defined', '.', 'Then', 'the', 'fileâ€™s', 'contents', 'are', 'read', 'and', 'stored', 'in', 'the', 'variable', 'named', 'data', '.', 'All', 'the', 'occurrences', 'of', 'the', 'newline', 'character', 'in', 'the', 'variable', 'data', 'are', 'replaced', 'with', 'the', 'empty', 'string', '(', 'nothing', ')', '.', 'In', 'the', 'end', ',', 'the', 'data', 'after', 'stripping', 'the', 'newlines', 'are', 'displayed', '.', 'The', 'task', 'could', 'also', 'be', 'performed', 'using', 'the', 'split', 'function', ',', 'a', 'default', 'function', 'in', 'all', 'Python', 'distributions', '.', 'The', 'function', 'takes', 'in', 'an', 'argument', '(', 'optional', ')', 'a', 'character', '(', 'or', 'string', ')', 'and', 'splits', 'the', 'string', 'based', 'on', 'the', 'occurrence', 'of', 'that', 'character', 'in', 'it', '.', 'Firstly', 'the', 'file', 'is', 'read', 'and', 'stored', 'in', 'a', 'variable', 'as', 'before', '.', 'Then', 'the', 'variable', 'is', 'passed', 'through', 'the', 'split', 'function', ',', 'which', 'splits', 'the', 'string', 'and', 'creates', 'a', 'list', 'based', 'on', 'the', 'occurrences', 'of', 'the', 'passed', 'argument', '.', 'In', 'this', 'case', ',', 'it', 'was', 'the', 'newline', 'character', '.', 'Thus', 'after', 'this', 'process', ',', 'we', 'ended', 'up', 'with', 'a', 'list', 'containing', 'substrings', 'of', 'the', 'original', 'strings', '.', 'The', 'Splitlines', 'is', 'a', 'function', 'that', 'splits/breaks', 'a', 'string', 'based', 'on', 'the', 'occurrence', 'of', 'escape', 'sequences', '.', 'The', 'function', 'converts', 'the', 'string', 'to', 'a', 'list', 'upon', 'stripping', 'the', 'control', 'characters', '.', 'Hence', ',', 'all', 'the', 'list', 'elements', 'must', 'be', 'iterated', 'to', 'get', 'the', 'final', 'string', '.', 'This', 'method', 'is', 'almost', 'identical', 'to', 'the', 'split', 'method', 'described', 'earlier', '.', 'The', 'only', 'difference', 'is', 'that', 'the', 'split', 'lines', 'function', 'does', 'not', 'require', 'any', 'argument', 'and', 'is', 'made', 'to', 'work', 'only', 'with', 'line', 'boundaries', '.', 'Hence', ',', 'the', 'splitting', 'of', 'data', 'would', 'be', 'made', 'on', 'any', 'occurrence', 'of', 'a', 'line', 'boundary', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize as wd\n",
    "token1 = wt(sent1)\n",
    "print(token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNoS9dc-fhgX",
    "outputId": "00c51aac-e26a-4a6c-90ad-7d8f174041d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'an', 'interdisciplinary', 'subfield', 'of', 'computer', 'science', 'and', 'linguistics', '.']\n",
      "['It', 'is', 'primarily', 'concerned', 'with', 'giving', 'computers', 'the', 'ability', 'to', 'support', 'and', 'manipulate', 'human', 'language', '.']\n",
      "['It', 'involves', 'processing', 'natural', 'language', 'datasets', ',', 'such', 'as', 'text', 'corpora', 'or', 'speech', 'corpora', ',', 'using', 'either', 'rule-based', 'or', 'probabilistic', '(', 'i.e', '.']\n",
      "['statistical', 'and', ',', 'most', 'recently', ',', 'neural', 'network-based', ')', 'machine', 'learning', 'approaches', '.']\n",
      "['The', 'goal', 'is', 'a', 'computer', 'capable', 'of', 'understanding', 'the', 'contents', 'of', 'documents', ',', 'including', 'the', 'contextual', 'nuances', 'of', 'the', 'language', 'within', 'them', '.']\n",
      "['The', 'technology', 'can', 'then', 'accurately', 'extract', 'information', 'and', 'insights', 'contained', 'in', 'the', 'documents', 'as', 'well', 'as', 'categorize', 'and', 'organize', 'the', 'documents', 'themselves', '.']\n",
      "['Challenges', 'in', 'natural', 'language', 'processing', 'frequently', 'involve', 'speech', 'recognition', ',', 'natural-language', 'understanding', ',', 'and', 'natural-language', 'generation', '.']\n",
      "['Up', 'to', 'the', '1980s', ',', 'most', 'natural', 'language', 'processing', 'systems', 'were', 'based', 'on', 'complex', 'sets', 'of', 'hand-written', 'rules', '.']\n",
      "['Starting', 'in', 'the', 'late', '1980s', ',', 'however', ',', 'there', 'was', 'a', 'revolution', 'in', 'natural', 'language', 'processing', 'with', 'the', 'introduction', 'of', 'machine', 'learning', 'algorithms', 'for', 'language', 'processing', '.']\n",
      "['This', 'was', 'due', 'to', 'both', 'the', 'steady', 'increase', 'in', 'computational', 'power', '(', 'see', 'Moore', \"'s\", 'law', ')', 'and', 'the', 'gradual', 'lessening', 'of', 'the', 'dominance', 'of', 'Chomskyan', 'theories', 'of', 'linguistics', '(', 'e.g', '.']\n",
      "['transformational', 'grammar', ')', ',', 'whose', 'theoretical', 'underpinnings', 'discouraged', 'the', 'sort', 'of', 'corpus', 'linguistics', 'that', 'underlies', 'the', 'machine-learning', 'approach', 'to', 'language', 'processing', '.']\n",
      "['Creating', 'a', 'single', 'sentence', 'with', '50', 'lines', 'can', 'be', 'quite', 'challenging', 'due', 'to', 'its', 'length', 'and', 'complexity', ',', 'but', 'I', 'can', 'provide', 'you', 'with', 'a', 'lengthy', 'sentence', 'that', 'attempts', 'to', 'cover', 'a', 'variety', 'of', 'topics', 'and', 'ideas', ':', 'It', 'is', 'quite', 'a', 'common', 'requirement', 'for', 'users', 'to', 'remove', 'certain', 'characters', 'from', 'their', 'text', 'files', 'while', 'displaying', '.']\n",
      "['This', 'is', 'done', 'to', 'assure', 'that', 'only', 'displayable', 'characters', 'are', 'displayed', 'or', 'data', 'should', 'be', 'displayed', 'in', 'a', 'specific', 'structure', '.']\n",
      "['This', 'article', 'will', 'teach', 'you', 'how', 'to', 'read', 'a', 'text', 'file', 'into', 'a', 'string', 'variable', 'and', 'strip', 'newlines', 'using', 'Python', '.']\n",
      "['The', 'task', 'could', 'be', 'performed', 'using', 'the', 'replace', 'function', ',', 'a', 'default', 'function', 'in', 'all', 'Python', 'distributions', '.']\n",
      "['Where', 'old', 'is', 'the', 'string', 'to', 'be', 'replaced', 'and', 'new', 'is', 'the', 'string', 'that', 'will', 'replace', 'it', '.']\n",
      "['Firstly', 'the', 'path', 'to', 'the', 'file', 'is', 'defined', '.']\n",
      "['Then', 'the', 'fileâ€™s', 'contents', 'are', 'read', 'and', 'stored', 'in', 'the', 'variable', 'named', 'data', '.']\n",
      "['All', 'the', 'occurrences', 'of', 'the', 'newline', 'character', 'in', 'the', 'variable', 'data', 'are', 'replaced', 'with', 'the', 'empty', 'string', '(', 'nothing', ')', '.']\n",
      "['In', 'the', 'end', ',', 'the', 'data', 'after', 'stripping', 'the', 'newlines', 'are', 'displayed', '.']\n",
      "['The', 'task', 'could', 'also', 'be', 'performed', 'using', 'the', 'split', 'function', ',', 'a', 'default', 'function', 'in', 'all', 'Python', 'distributions', '.']\n",
      "['The', 'function', 'takes', 'in', 'an', 'argument', '(', 'optional', ')', 'a', 'character', '(', 'or', 'string', ')', 'and', 'splits', 'the', 'string', 'based', 'on', 'the', 'occurrence', 'of', 'that', 'character', 'in', 'it', '.']\n",
      "['Firstly', 'the', 'file', 'is', 'read', 'and', 'stored', 'in', 'a', 'variable', 'as', 'before', '.']\n",
      "['Then', 'the', 'variable', 'is', 'passed', 'through', 'the', 'split', 'function', ',', 'which', 'splits', 'the', 'string', 'and', 'creates', 'a', 'list', 'based', 'on', 'the', 'occurrences', 'of', 'the', 'passed', 'argument', '.']\n",
      "['In', 'this', 'case', ',', 'it', 'was', 'the', 'newline', 'character', '.']\n",
      "['Thus', 'after', 'this', 'process', ',', 'we', 'ended', 'up', 'with', 'a', 'list', 'containing', 'substrings', 'of', 'the', 'original', 'strings', '.']\n",
      "['The', 'Splitlines', 'is', 'a', 'function', 'that', 'splits/breaks', 'a', 'string', 'based', 'on', 'the', 'occurrence', 'of', 'escape', 'sequences', '.']\n",
      "['The', 'function', 'converts', 'the', 'string', 'to', 'a', 'list', 'upon', 'stripping', 'the', 'control', 'characters', '.']\n",
      "['Hence', ',', 'all', 'the', 'list', 'elements', 'must', 'be', 'iterated', 'to', 'get', 'the', 'final', 'string', '.']\n",
      "['This', 'method', 'is', 'almost', 'identical', 'to', 'the', 'split', 'method', 'described', 'earlier', '.']\n",
      "['The', 'only', 'difference', 'is', 'that', 'the', 'split', 'lines', 'function', 'does', 'not', 'require', 'any', 'argument', 'and', 'is', 'made', 'to', 'work', 'only', 'with', 'line', 'boundaries', '.']\n",
      "['Hence', ',', 'the', 'splitting', 'of', 'data', 'would', 'be', 'made', 'on', 'any', 'occurrence', 'of', 'a', 'line', 'boundary', '.']\n"
     ]
    }
   ],
   "source": [
    "token2 = st(sent1)\n",
    "for i in token2:\n",
    "  print(wt(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BmXGLmeNgJMt",
    "outputId": "8f2e06ec-9c38-41d4-ac69-e25b12a7fb20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natur\n",
      "languag\n",
      "process\n",
      "(\n",
      "nlp\n",
      ")\n",
      "is\n",
      "an\n",
      "interdisciplinari\n",
      "subfield\n",
      "of\n",
      "comput\n",
      "scienc\n",
      "and\n",
      "linguist\n",
      ".\n",
      "it\n",
      "is\n",
      "primarili\n",
      "concern\n",
      "with\n",
      "give\n",
      "comput\n",
      "the\n",
      "abil\n",
      "to\n",
      "support\n",
      "and\n",
      "manipul\n",
      "human\n",
      "languag\n",
      ".\n",
      "it\n",
      "involv\n",
      "process\n",
      "natur\n",
      "languag\n",
      "dataset\n",
      ",\n",
      "such\n",
      "as\n",
      "text\n",
      "corpora\n",
      "or\n",
      "speech\n",
      "corpora\n",
      ",\n",
      "use\n",
      "either\n",
      "rule-bas\n",
      "or\n",
      "probabilist\n",
      "(\n",
      "i.e\n",
      ".\n",
      "statist\n",
      "and\n",
      ",\n",
      "most\n",
      "recent\n",
      ",\n",
      "neural\n",
      "network-bas\n",
      ")\n",
      "machin\n",
      "learn\n",
      "approach\n",
      ".\n",
      "the\n",
      "goal\n",
      "is\n",
      "a\n",
      "comput\n",
      "capabl\n",
      "of\n",
      "understand\n",
      "the\n",
      "content\n",
      "of\n",
      "document\n",
      ",\n",
      "includ\n",
      "the\n",
      "contextu\n",
      "nuanc\n",
      "of\n",
      "the\n",
      "languag\n",
      "within\n",
      "them\n",
      ".\n",
      "the\n",
      "technolog\n",
      "can\n",
      "then\n",
      "accur\n",
      "extract\n",
      "inform\n",
      "and\n",
      "insight\n",
      "contain\n",
      "in\n",
      "the\n",
      "document\n",
      "as\n",
      "well\n",
      "as\n",
      "categor\n",
      "and\n",
      "organ\n",
      "the\n",
      "document\n",
      "themselv\n",
      ".\n",
      "challeng\n",
      "in\n",
      "natur\n",
      "languag\n",
      "process\n",
      "frequent\n",
      "involv\n",
      "speech\n",
      "recognit\n",
      ",\n",
      "natural-languag\n",
      "understand\n",
      ",\n",
      "and\n",
      "natural-languag\n",
      "gener\n",
      ".\n",
      "up\n",
      "to\n",
      "the\n",
      "1980\n",
      ",\n",
      "most\n",
      "natur\n",
      "languag\n",
      "process\n",
      "system\n",
      "were\n",
      "base\n",
      "on\n",
      "complex\n",
      "set\n",
      "of\n",
      "hand-written\n",
      "rule\n",
      ".\n",
      "start\n",
      "in\n",
      "the\n",
      "late\n",
      "1980\n",
      ",\n",
      "howev\n",
      ",\n",
      "there\n",
      "wa\n",
      "a\n",
      "revolut\n",
      "in\n",
      "natur\n",
      "languag\n",
      "process\n",
      "with\n",
      "the\n",
      "introduct\n",
      "of\n",
      "machin\n",
      "learn\n",
      "algorithm\n",
      "for\n",
      "languag\n",
      "process\n",
      ".\n",
      "thi\n",
      "wa\n",
      "due\n",
      "to\n",
      "both\n",
      "the\n",
      "steadi\n",
      "increas\n",
      "in\n",
      "comput\n",
      "power\n",
      "(\n",
      "see\n",
      "moor\n",
      "'s\n",
      "law\n",
      ")\n",
      "and\n",
      "the\n",
      "gradual\n",
      "lessen\n",
      "of\n",
      "the\n",
      "domin\n",
      "of\n",
      "chomskyan\n",
      "theori\n",
      "of\n",
      "linguist\n",
      "(\n",
      "e.g\n",
      ".\n",
      "transform\n",
      "grammar\n",
      ")\n",
      ",\n",
      "whose\n",
      "theoret\n",
      "underpin\n",
      "discourag\n",
      "the\n",
      "sort\n",
      "of\n",
      "corpu\n",
      "linguist\n",
      "that\n",
      "underli\n",
      "the\n",
      "machine-learn\n",
      "approach\n",
      "to\n",
      "languag\n",
      "process\n",
      ".\n",
      "creat\n",
      "a\n",
      "singl\n",
      "sentenc\n",
      "with\n",
      "50\n",
      "line\n",
      "can\n",
      "be\n",
      "quit\n",
      "challeng\n",
      "due\n",
      "to\n",
      "it\n",
      "length\n",
      "and\n",
      "complex\n",
      ",\n",
      "but\n",
      "i\n",
      "can\n",
      "provid\n",
      "you\n",
      "with\n",
      "a\n",
      "lengthi\n",
      "sentenc\n",
      "that\n",
      "attempt\n",
      "to\n",
      "cover\n",
      "a\n",
      "varieti\n",
      "of\n",
      "topic\n",
      "and\n",
      "idea\n",
      ":\n",
      "it\n",
      "is\n",
      "quit\n",
      "a\n",
      "common\n",
      "requir\n",
      "for\n",
      "user\n",
      "to\n",
      "remov\n",
      "certain\n",
      "charact\n",
      "from\n",
      "their\n",
      "text\n",
      "file\n",
      "while\n",
      "display\n",
      ".\n",
      "thi\n",
      "is\n",
      "done\n",
      "to\n",
      "assur\n",
      "that\n",
      "onli\n",
      "display\n",
      "charact\n",
      "are\n",
      "display\n",
      "or\n",
      "data\n",
      "should\n",
      "be\n",
      "display\n",
      "in\n",
      "a\n",
      "specif\n",
      "structur\n",
      ".\n",
      "thi\n",
      "articl\n",
      "will\n",
      "teach\n",
      "you\n",
      "how\n",
      "to\n",
      "read\n",
      "a\n",
      "text\n",
      "file\n",
      "into\n",
      "a\n",
      "string\n",
      "variabl\n",
      "and\n",
      "strip\n",
      "newlin\n",
      "use\n",
      "python\n",
      ".\n",
      "the\n",
      "task\n",
      "could\n",
      "be\n",
      "perform\n",
      "use\n",
      "the\n",
      "replac\n",
      "function\n",
      ",\n",
      "a\n",
      "default\n",
      "function\n",
      "in\n",
      "all\n",
      "python\n",
      "distribut\n",
      ".\n",
      "where\n",
      "old\n",
      "is\n",
      "the\n",
      "string\n",
      "to\n",
      "be\n",
      "replac\n",
      "and\n",
      "new\n",
      "is\n",
      "the\n",
      "string\n",
      "that\n",
      "will\n",
      "replac\n",
      "it\n",
      ".\n",
      "firstli\n",
      "the\n",
      "path\n",
      "to\n",
      "the\n",
      "file\n",
      "is\n",
      "defin\n",
      ".\n",
      "then\n",
      "the\n",
      "fileâ€™\n",
      "content\n",
      "are\n",
      "read\n",
      "and\n",
      "store\n",
      "in\n",
      "the\n",
      "variabl\n",
      "name\n",
      "data\n",
      ".\n",
      "all\n",
      "the\n",
      "occurr\n",
      "of\n",
      "the\n",
      "newlin\n",
      "charact\n",
      "in\n",
      "the\n",
      "variabl\n",
      "data\n",
      "are\n",
      "replac\n",
      "with\n",
      "the\n",
      "empti\n",
      "string\n",
      "(\n",
      "noth\n",
      ")\n",
      ".\n",
      "in\n",
      "the\n",
      "end\n",
      ",\n",
      "the\n",
      "data\n",
      "after\n",
      "strip\n",
      "the\n",
      "newlin\n",
      "are\n",
      "display\n",
      ".\n",
      "the\n",
      "task\n",
      "could\n",
      "also\n",
      "be\n",
      "perform\n",
      "use\n",
      "the\n",
      "split\n",
      "function\n",
      ",\n",
      "a\n",
      "default\n",
      "function\n",
      "in\n",
      "all\n",
      "python\n",
      "distribut\n",
      ".\n",
      "the\n",
      "function\n",
      "take\n",
      "in\n",
      "an\n",
      "argument\n",
      "(\n",
      "option\n",
      ")\n",
      "a\n",
      "charact\n",
      "(\n",
      "or\n",
      "string\n",
      ")\n",
      "and\n",
      "split\n",
      "the\n",
      "string\n",
      "base\n",
      "on\n",
      "the\n",
      "occurr\n",
      "of\n",
      "that\n",
      "charact\n",
      "in\n",
      "it\n",
      ".\n",
      "firstli\n",
      "the\n",
      "file\n",
      "is\n",
      "read\n",
      "and\n",
      "store\n",
      "in\n",
      "a\n",
      "variabl\n",
      "as\n",
      "befor\n",
      ".\n",
      "then\n",
      "the\n",
      "variabl\n",
      "is\n",
      "pass\n",
      "through\n",
      "the\n",
      "split\n",
      "function\n",
      ",\n",
      "which\n",
      "split\n",
      "the\n",
      "string\n",
      "and\n",
      "creat\n",
      "a\n",
      "list\n",
      "base\n",
      "on\n",
      "the\n",
      "occurr\n",
      "of\n",
      "the\n",
      "pass\n",
      "argument\n",
      ".\n",
      "in\n",
      "thi\n",
      "case\n",
      ",\n",
      "it\n",
      "wa\n",
      "the\n",
      "newlin\n",
      "charact\n",
      ".\n",
      "thu\n",
      "after\n",
      "thi\n",
      "process\n",
      ",\n",
      "we\n",
      "end\n",
      "up\n",
      "with\n",
      "a\n",
      "list\n",
      "contain\n",
      "substr\n",
      "of\n",
      "the\n",
      "origin\n",
      "string\n",
      ".\n",
      "the\n",
      "splitlin\n",
      "is\n",
      "a\n",
      "function\n",
      "that\n",
      "splits/break\n",
      "a\n",
      "string\n",
      "base\n",
      "on\n",
      "the\n",
      "occurr\n",
      "of\n",
      "escap\n",
      "sequenc\n",
      ".\n",
      "the\n",
      "function\n",
      "convert\n",
      "the\n",
      "string\n",
      "to\n",
      "a\n",
      "list\n",
      "upon\n",
      "strip\n",
      "the\n",
      "control\n",
      "charact\n",
      ".\n",
      "henc\n",
      ",\n",
      "all\n",
      "the\n",
      "list\n",
      "element\n",
      "must\n",
      "be\n",
      "iter\n",
      "to\n",
      "get\n",
      "the\n",
      "final\n",
      "string\n",
      ".\n",
      "thi\n",
      "method\n",
      "is\n",
      "almost\n",
      "ident\n",
      "to\n",
      "the\n",
      "split\n",
      "method\n",
      "describ\n",
      "earlier\n",
      ".\n",
      "the\n",
      "onli\n",
      "differ\n",
      "is\n",
      "that\n",
      "the\n",
      "split\n",
      "line\n",
      "function\n",
      "doe\n",
      "not\n",
      "requir\n",
      "ani\n",
      "argument\n",
      "and\n",
      "is\n",
      "made\n",
      "to\n",
      "work\n",
      "onli\n",
      "with\n",
      "line\n",
      "boundari\n",
      ".\n",
      "henc\n",
      ",\n",
      "the\n",
      "split\n",
      "of\n",
      "data\n",
      "would\n",
      "be\n",
      "made\n",
      "on\n",
      "ani\n",
      "occurr\n",
      "of\n",
      "a\n",
      "line\n",
      "boundari\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "for i in token1:\n",
    "  print(ps.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTd13mj2iDld",
    "outputId": "d365c7d1-cec7-4fc7-869a-6506de3e904e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nat\n",
      "langu\n",
      "process\n",
      "(\n",
      "nlp\n",
      ")\n",
      "is\n",
      "an\n",
      "interdisciplin\n",
      "subfield\n",
      "of\n",
      "comput\n",
      "sci\n",
      "and\n",
      "lingu\n",
      ".\n",
      "it\n",
      "is\n",
      "prim\n",
      "concern\n",
      "with\n",
      "giv\n",
      "comput\n",
      "the\n",
      "abl\n",
      "to\n",
      "support\n",
      "and\n",
      "manip\n",
      "hum\n",
      "langu\n",
      ".\n",
      "it\n",
      "involv\n",
      "process\n",
      "nat\n",
      "langu\n",
      "dataset\n",
      ",\n",
      "such\n",
      "as\n",
      "text\n",
      "corpor\n",
      "or\n",
      "speech\n",
      "corpor\n",
      ",\n",
      "us\n",
      "eith\n",
      "rule-based\n",
      "or\n",
      "prob\n",
      "(\n",
      "i.e\n",
      ".\n",
      "stat\n",
      "and\n",
      ",\n",
      "most\n",
      "rec\n",
      ",\n",
      "neur\n",
      "network-based\n",
      ")\n",
      "machin\n",
      "learn\n",
      "approach\n",
      ".\n",
      "the\n",
      "goal\n",
      "is\n",
      "a\n",
      "comput\n",
      "cap\n",
      "of\n",
      "understand\n",
      "the\n",
      "cont\n",
      "of\n",
      "docu\n",
      ",\n",
      "includ\n",
      "the\n",
      "context\n",
      "nuant\n",
      "of\n",
      "the\n",
      "langu\n",
      "within\n",
      "them\n",
      ".\n",
      "the\n",
      "technolog\n",
      "can\n",
      "then\n",
      "acc\n",
      "extract\n",
      "inform\n",
      "and\n",
      "insight\n",
      "contain\n",
      "in\n",
      "the\n",
      "docu\n",
      "as\n",
      "wel\n",
      "as\n",
      "categ\n",
      "and\n",
      "org\n",
      "the\n",
      "docu\n",
      "themselv\n",
      ".\n",
      "challeng\n",
      "in\n",
      "nat\n",
      "langu\n",
      "process\n",
      "frequ\n",
      "involv\n",
      "speech\n",
      "recognit\n",
      ",\n",
      "natural-language\n",
      "understand\n",
      ",\n",
      "and\n",
      "natural-language\n",
      "gen\n",
      ".\n",
      "up\n",
      "to\n",
      "the\n",
      "1980s\n",
      ",\n",
      "most\n",
      "nat\n",
      "langu\n",
      "process\n",
      "system\n",
      "wer\n",
      "bas\n",
      "on\n",
      "complex\n",
      "set\n",
      "of\n",
      "hand-written\n",
      "rul\n",
      ".\n",
      "start\n",
      "in\n",
      "the\n",
      "lat\n",
      "1980s\n",
      ",\n",
      "howev\n",
      ",\n",
      "ther\n",
      "was\n",
      "a\n",
      "revolv\n",
      "in\n",
      "nat\n",
      "langu\n",
      "process\n",
      "with\n",
      "the\n",
      "introduc\n",
      "of\n",
      "machin\n",
      "learn\n",
      "algorithm\n",
      "for\n",
      "langu\n",
      "process\n",
      ".\n",
      "thi\n",
      "was\n",
      "due\n",
      "to\n",
      "both\n",
      "the\n",
      "steady\n",
      "increas\n",
      "in\n",
      "comput\n",
      "pow\n",
      "(\n",
      "see\n",
      "moor\n",
      "'s\n",
      "law\n",
      ")\n",
      "and\n",
      "the\n",
      "grad\n",
      "less\n",
      "of\n",
      "the\n",
      "domin\n",
      "of\n",
      "chomsky\n",
      "the\n",
      "of\n",
      "lingu\n",
      "(\n",
      "e.g\n",
      ".\n",
      "transform\n",
      "gramm\n",
      ")\n",
      ",\n",
      "whos\n",
      "theoret\n",
      "underpin\n",
      "disco\n",
      "the\n",
      "sort\n",
      "of\n",
      "corp\n",
      "lingu\n",
      "that\n",
      "und\n",
      "the\n",
      "machine-learning\n",
      "approach\n",
      "to\n",
      "langu\n",
      "process\n",
      ".\n",
      "cre\n",
      "a\n",
      "singl\n",
      "sent\n",
      "with\n",
      "50\n",
      "lin\n",
      "can\n",
      "be\n",
      "quit\n",
      "challeng\n",
      "due\n",
      "to\n",
      "it\n",
      "leng\n",
      "and\n",
      "complex\n",
      ",\n",
      "but\n",
      "i\n",
      "can\n",
      "provid\n",
      "you\n",
      "with\n",
      "a\n",
      "lengthy\n",
      "sent\n",
      "that\n",
      "attempt\n",
      "to\n",
      "cov\n",
      "a\n",
      "vary\n",
      "of\n",
      "top\n",
      "and\n",
      "idea\n",
      ":\n",
      "it\n",
      "is\n",
      "quit\n",
      "a\n",
      "common\n",
      "requir\n",
      "for\n",
      "us\n",
      "to\n",
      "remov\n",
      "certain\n",
      "charact\n",
      "from\n",
      "their\n",
      "text\n",
      "fil\n",
      "whil\n",
      "display\n",
      ".\n",
      "thi\n",
      "is\n",
      "don\n",
      "to\n",
      "ass\n",
      "that\n",
      "on\n",
      "display\n",
      "charact\n",
      "ar\n",
      "display\n",
      "or\n",
      "dat\n",
      "should\n",
      "be\n",
      "display\n",
      "in\n",
      "a\n",
      "spec\n",
      "structure\n",
      ".\n",
      "thi\n",
      "artic\n",
      "wil\n",
      "teach\n",
      "you\n",
      "how\n",
      "to\n",
      "read\n",
      "a\n",
      "text\n",
      "fil\n",
      "into\n",
      "a\n",
      "string\n",
      "vary\n",
      "and\n",
      "strip\n",
      "newlin\n",
      "us\n",
      "python\n",
      ".\n",
      "the\n",
      "task\n",
      "could\n",
      "be\n",
      "perform\n",
      "us\n",
      "the\n",
      "replac\n",
      "funct\n",
      ",\n",
      "a\n",
      "default\n",
      "funct\n",
      "in\n",
      "al\n",
      "python\n",
      "distribut\n",
      ".\n",
      "wher\n",
      "old\n",
      "is\n",
      "the\n",
      "string\n",
      "to\n",
      "be\n",
      "replac\n",
      "and\n",
      "new\n",
      "is\n",
      "the\n",
      "string\n",
      "that\n",
      "wil\n",
      "replac\n",
      "it\n",
      ".\n",
      "first\n",
      "the\n",
      "path\n",
      "to\n",
      "the\n",
      "fil\n",
      "is\n",
      "defin\n",
      ".\n",
      "then\n",
      "the\n",
      "fileâ€™s\n",
      "cont\n",
      "ar\n",
      "read\n",
      "and\n",
      "stor\n",
      "in\n",
      "the\n",
      "vary\n",
      "nam\n",
      "dat\n",
      ".\n",
      "al\n",
      "the\n",
      "occur\n",
      "of\n",
      "the\n",
      "newlin\n",
      "charact\n",
      "in\n",
      "the\n",
      "vary\n",
      "dat\n",
      "ar\n",
      "replac\n",
      "with\n",
      "the\n",
      "empty\n",
      "string\n",
      "(\n",
      "noth\n",
      ")\n",
      ".\n",
      "in\n",
      "the\n",
      "end\n",
      ",\n",
      "the\n",
      "dat\n",
      "aft\n",
      "stripping\n",
      "the\n",
      "newlin\n",
      "ar\n",
      "display\n",
      ".\n",
      "the\n",
      "task\n",
      "could\n",
      "also\n",
      "be\n",
      "perform\n",
      "us\n",
      "the\n",
      "split\n",
      "funct\n",
      ",\n",
      "a\n",
      "default\n",
      "funct\n",
      "in\n",
      "al\n",
      "python\n",
      "distribut\n",
      ".\n",
      "the\n",
      "funct\n",
      "tak\n",
      "in\n",
      "an\n",
      "argu\n",
      "(\n",
      "opt\n",
      ")\n",
      "a\n",
      "charact\n",
      "(\n",
      "or\n",
      "string\n",
      ")\n",
      "and\n",
      "splits\n",
      "the\n",
      "string\n",
      "bas\n",
      "on\n",
      "the\n",
      "occur\n",
      "of\n",
      "that\n",
      "charact\n",
      "in\n",
      "it\n",
      ".\n",
      "first\n",
      "the\n",
      "fil\n",
      "is\n",
      "read\n",
      "and\n",
      "stor\n",
      "in\n",
      "a\n",
      "vary\n",
      "as\n",
      "bef\n",
      ".\n",
      "then\n",
      "the\n",
      "vary\n",
      "is\n",
      "pass\n",
      "through\n",
      "the\n",
      "split\n",
      "funct\n",
      ",\n",
      "which\n",
      "splits\n",
      "the\n",
      "string\n",
      "and\n",
      "cre\n",
      "a\n",
      "list\n",
      "bas\n",
      "on\n",
      "the\n",
      "occur\n",
      "of\n",
      "the\n",
      "pass\n",
      "argu\n",
      ".\n",
      "in\n",
      "thi\n",
      "cas\n",
      ",\n",
      "it\n",
      "was\n",
      "the\n",
      "newlin\n",
      "charact\n",
      ".\n",
      "thu\n",
      "aft\n",
      "thi\n",
      "process\n",
      ",\n",
      "we\n",
      "end\n",
      "up\n",
      "with\n",
      "a\n",
      "list\n",
      "contain\n",
      "subst\n",
      "of\n",
      "the\n",
      "origin\n",
      "strings\n",
      ".\n",
      "the\n",
      "splitlines\n",
      "is\n",
      "a\n",
      "funct\n",
      "that\n",
      "splits/breaks\n",
      "a\n",
      "string\n",
      "bas\n",
      "on\n",
      "the\n",
      "occur\n",
      "of\n",
      "escap\n",
      "sequ\n",
      ".\n",
      "the\n",
      "funct\n",
      "convert\n",
      "the\n",
      "string\n",
      "to\n",
      "a\n",
      "list\n",
      "upon\n",
      "stripping\n",
      "the\n",
      "control\n",
      "charact\n",
      ".\n",
      "hent\n",
      ",\n",
      "al\n",
      "the\n",
      "list\n",
      "el\n",
      "must\n",
      "be\n",
      "it\n",
      "to\n",
      "get\n",
      "the\n",
      "fin\n",
      "string\n",
      ".\n",
      "thi\n",
      "method\n",
      "is\n",
      "almost\n",
      "id\n",
      "to\n",
      "the\n",
      "split\n",
      "method\n",
      "describ\n",
      "ear\n",
      ".\n",
      "the\n",
      "on\n",
      "diff\n",
      "is\n",
      "that\n",
      "the\n",
      "split\n",
      "lin\n",
      "funct\n",
      "doe\n",
      "not\n",
      "requir\n",
      "any\n",
      "argu\n",
      "and\n",
      "is\n",
      "mad\n",
      "to\n",
      "work\n",
      "on\n",
      "with\n",
      "lin\n",
      "bound\n",
      ".\n",
      "hent\n",
      ",\n",
      "the\n",
      "splitting\n",
      "of\n",
      "dat\n",
      "would\n",
      "be\n",
      "mad\n",
      "on\n",
      "any\n",
      "occur\n",
      "of\n",
      "a\n",
      "lin\n",
      "bound\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "ps = LancasterStemmer()\n",
    "for i in token1:\n",
    "  print(ps.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5CcGYMfJiPek",
    "outputId": "5627a692-a266-4c57-f3f7-064b78c592d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natur\n",
      "languag\n",
      "process\n",
      "(\n",
      "nlp\n",
      ")\n",
      "is\n",
      "an\n",
      "interdisciplinari\n",
      "subfield\n",
      "of\n",
      "comput\n",
      "scienc\n",
      "and\n",
      "linguist\n",
      ".\n",
      "it\n",
      "is\n",
      "primarili\n",
      "concern\n",
      "with\n",
      "give\n",
      "comput\n",
      "the\n",
      "abil\n",
      "to\n",
      "support\n",
      "and\n",
      "manipul\n",
      "human\n",
      "languag\n",
      ".\n",
      "it\n",
      "involv\n",
      "process\n",
      "natur\n",
      "languag\n",
      "dataset\n",
      ",\n",
      "such\n",
      "as\n",
      "text\n",
      "corpora\n",
      "or\n",
      "speech\n",
      "corpora\n",
      ",\n",
      "use\n",
      "either\n",
      "rule-bas\n",
      "or\n",
      "probabilist\n",
      "(\n",
      "i.e\n",
      ".\n",
      "statist\n",
      "and\n",
      ",\n",
      "most\n",
      "recent\n",
      ",\n",
      "neural\n",
      "network-bas\n",
      ")\n",
      "machin\n",
      "learn\n",
      "approach\n",
      ".\n",
      "the\n",
      "goal\n",
      "is\n",
      "a\n",
      "comput\n",
      "capabl\n",
      "of\n",
      "understand\n",
      "the\n",
      "content\n",
      "of\n",
      "document\n",
      ",\n",
      "includ\n",
      "the\n",
      "contextu\n",
      "nuanc\n",
      "of\n",
      "the\n",
      "languag\n",
      "within\n",
      "them\n",
      ".\n",
      "the\n",
      "technolog\n",
      "can\n",
      "then\n",
      "accur\n",
      "extract\n",
      "inform\n",
      "and\n",
      "insight\n",
      "contain\n",
      "in\n",
      "the\n",
      "document\n",
      "as\n",
      "well\n",
      "as\n",
      "categor\n",
      "and\n",
      "organ\n",
      "the\n",
      "document\n",
      "themselv\n",
      ".\n",
      "challeng\n",
      "in\n",
      "natur\n",
      "languag\n",
      "process\n",
      "frequent\n",
      "involv\n",
      "speech\n",
      "recognit\n",
      ",\n",
      "natural-languag\n",
      "understand\n",
      ",\n",
      "and\n",
      "natural-languag\n",
      "generat\n",
      ".\n",
      "up\n",
      "to\n",
      "the\n",
      "1980s\n",
      ",\n",
      "most\n",
      "natur\n",
      "languag\n",
      "process\n",
      "system\n",
      "were\n",
      "base\n",
      "on\n",
      "complex\n",
      "set\n",
      "of\n",
      "hand-written\n",
      "rule\n",
      ".\n",
      "start\n",
      "in\n",
      "the\n",
      "late\n",
      "1980s\n",
      ",\n",
      "howev\n",
      ",\n",
      "there\n",
      "was\n",
      "a\n",
      "revolut\n",
      "in\n",
      "natur\n",
      "languag\n",
      "process\n",
      "with\n",
      "the\n",
      "introduct\n",
      "of\n",
      "machin\n",
      "learn\n",
      "algorithm\n",
      "for\n",
      "languag\n",
      "process\n",
      ".\n",
      "this\n",
      "was\n",
      "due\n",
      "to\n",
      "both\n",
      "the\n",
      "steadi\n",
      "increas\n",
      "in\n",
      "comput\n",
      "power\n",
      "(\n",
      "see\n",
      "moor\n",
      "'s\n",
      "law\n",
      ")\n",
      "and\n",
      "the\n",
      "gradual\n",
      "lessen\n",
      "of\n",
      "the\n",
      "domin\n",
      "of\n",
      "chomskyan\n",
      "theori\n",
      "of\n",
      "linguist\n",
      "(\n",
      "e.g\n",
      ".\n",
      "transform\n",
      "grammar\n",
      ")\n",
      ",\n",
      "whose\n",
      "theoret\n",
      "underpin\n",
      "discourag\n",
      "the\n",
      "sort\n",
      "of\n",
      "corpus\n",
      "linguist\n",
      "that\n",
      "under\n",
      "the\n",
      "machine-learn\n",
      "approach\n",
      "to\n",
      "languag\n",
      "process\n",
      ".\n",
      "creat\n",
      "a\n",
      "singl\n",
      "sentenc\n",
      "with\n",
      "50\n",
      "line\n",
      "can\n",
      "be\n",
      "quit\n",
      "challeng\n",
      "due\n",
      "to\n",
      "it\n",
      "length\n",
      "and\n",
      "complex\n",
      ",\n",
      "but\n",
      "i\n",
      "can\n",
      "provid\n",
      "you\n",
      "with\n",
      "a\n",
      "lengthi\n",
      "sentenc\n",
      "that\n",
      "attempt\n",
      "to\n",
      "cover\n",
      "a\n",
      "varieti\n",
      "of\n",
      "topic\n",
      "and\n",
      "idea\n",
      ":\n",
      "it\n",
      "is\n",
      "quit\n",
      "a\n",
      "common\n",
      "requir\n",
      "for\n",
      "user\n",
      "to\n",
      "remov\n",
      "certain\n",
      "charact\n",
      "from\n",
      "their\n",
      "text\n",
      "file\n",
      "while\n",
      "display\n",
      ".\n",
      "this\n",
      "is\n",
      "done\n",
      "to\n",
      "assur\n",
      "that\n",
      "onli\n",
      "display\n",
      "charact\n",
      "are\n",
      "display\n",
      "or\n",
      "data\n",
      "should\n",
      "be\n",
      "display\n",
      "in\n",
      "a\n",
      "specif\n",
      "structur\n",
      ".\n",
      "this\n",
      "articl\n",
      "will\n",
      "teach\n",
      "you\n",
      "how\n",
      "to\n",
      "read\n",
      "a\n",
      "text\n",
      "file\n",
      "into\n",
      "a\n",
      "string\n",
      "variabl\n",
      "and\n",
      "strip\n",
      "newlin\n",
      "use\n",
      "python\n",
      ".\n",
      "the\n",
      "task\n",
      "could\n",
      "be\n",
      "perform\n",
      "use\n",
      "the\n",
      "replac\n",
      "function\n",
      ",\n",
      "a\n",
      "default\n",
      "function\n",
      "in\n",
      "all\n",
      "python\n",
      "distribut\n",
      ".\n",
      "where\n",
      "old\n",
      "is\n",
      "the\n",
      "string\n",
      "to\n",
      "be\n",
      "replac\n",
      "and\n",
      "new\n",
      "is\n",
      "the\n",
      "string\n",
      "that\n",
      "will\n",
      "replac\n",
      "it\n",
      ".\n",
      "first\n",
      "the\n",
      "path\n",
      "to\n",
      "the\n",
      "file\n",
      "is\n",
      "defin\n",
      ".\n",
      "then\n",
      "the\n",
      "fileâ€™\n",
      "content\n",
      "are\n",
      "read\n",
      "and\n",
      "store\n",
      "in\n",
      "the\n",
      "variabl\n",
      "name\n",
      "data\n",
      ".\n",
      "all\n",
      "the\n",
      "occurr\n",
      "of\n",
      "the\n",
      "newlin\n",
      "charact\n",
      "in\n",
      "the\n",
      "variabl\n",
      "data\n",
      "are\n",
      "replac\n",
      "with\n",
      "the\n",
      "empti\n",
      "string\n",
      "(\n",
      "noth\n",
      ")\n",
      ".\n",
      "in\n",
      "the\n",
      "end\n",
      ",\n",
      "the\n",
      "data\n",
      "after\n",
      "strip\n",
      "the\n",
      "newlin\n",
      "are\n",
      "display\n",
      ".\n",
      "the\n",
      "task\n",
      "could\n",
      "also\n",
      "be\n",
      "perform\n",
      "use\n",
      "the\n",
      "split\n",
      "function\n",
      ",\n",
      "a\n",
      "default\n",
      "function\n",
      "in\n",
      "all\n",
      "python\n",
      "distribut\n",
      ".\n",
      "the\n",
      "function\n",
      "take\n",
      "in\n",
      "an\n",
      "argument\n",
      "(\n",
      "option\n",
      ")\n",
      "a\n",
      "charact\n",
      "(\n",
      "or\n",
      "string\n",
      ")\n",
      "and\n",
      "split\n",
      "the\n",
      "string\n",
      "base\n",
      "on\n",
      "the\n",
      "occurr\n",
      "of\n",
      "that\n",
      "charact\n",
      "in\n",
      "it\n",
      ".\n",
      "first\n",
      "the\n",
      "file\n",
      "is\n",
      "read\n",
      "and\n",
      "store\n",
      "in\n",
      "a\n",
      "variabl\n",
      "as\n",
      "befor\n",
      ".\n",
      "then\n",
      "the\n",
      "variabl\n",
      "is\n",
      "pass\n",
      "through\n",
      "the\n",
      "split\n",
      "function\n",
      ",\n",
      "which\n",
      "split\n",
      "the\n",
      "string\n",
      "and\n",
      "creat\n",
      "a\n",
      "list\n",
      "base\n",
      "on\n",
      "the\n",
      "occurr\n",
      "of\n",
      "the\n",
      "pass\n",
      "argument\n",
      ".\n",
      "in\n",
      "this\n",
      "case\n",
      ",\n",
      "it\n",
      "was\n",
      "the\n",
      "newlin\n",
      "charact\n",
      ".\n",
      "thus\n",
      "after\n",
      "this\n",
      "process\n",
      ",\n",
      "we\n",
      "end\n",
      "up\n",
      "with\n",
      "a\n",
      "list\n",
      "contain\n",
      "substr\n",
      "of\n",
      "the\n",
      "origin\n",
      "string\n",
      ".\n",
      "the\n",
      "splitlin\n",
      "is\n",
      "a\n",
      "function\n",
      "that\n",
      "splits/break\n",
      "a\n",
      "string\n",
      "base\n",
      "on\n",
      "the\n",
      "occurr\n",
      "of\n",
      "escap\n",
      "sequenc\n",
      ".\n",
      "the\n",
      "function\n",
      "convert\n",
      "the\n",
      "string\n",
      "to\n",
      "a\n",
      "list\n",
      "upon\n",
      "strip\n",
      "the\n",
      "control\n",
      "charact\n",
      ".\n",
      "henc\n",
      ",\n",
      "all\n",
      "the\n",
      "list\n",
      "element\n",
      "must\n",
      "be\n",
      "iter\n",
      "to\n",
      "get\n",
      "the\n",
      "final\n",
      "string\n",
      ".\n",
      "this\n",
      "method\n",
      "is\n",
      "almost\n",
      "ident\n",
      "to\n",
      "the\n",
      "split\n",
      "method\n",
      "describ\n",
      "earlier\n",
      ".\n",
      "the\n",
      "onli\n",
      "differ\n",
      "is\n",
      "that\n",
      "the\n",
      "split\n",
      "line\n",
      "function\n",
      "doe\n",
      "not\n",
      "requir\n",
      "ani\n",
      "argument\n",
      "and\n",
      "is\n",
      "made\n",
      "to\n",
      "work\n",
      "onli\n",
      "with\n",
      "line\n",
      "boundari\n",
      ".\n",
      "henc\n",
      ",\n",
      "the\n",
      "split\n",
      "of\n",
      "data\n",
      "would\n",
      "be\n",
      "made\n",
      "on\n",
      "ani\n",
      "occurr\n",
      "of\n",
      "a\n",
      "line\n",
      "boundari\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "ps = SnowballStemmer(language='english')\n",
    "for i in token1:\n",
    "  print(ps.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZSyz71kiU5N",
    "outputId": "771fac69-e0b2-4c3b-ae21-acc0027bf05c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "language\n",
      "processing\n",
      "(\n",
      "NLP\n",
      ")\n",
      "is\n",
      "an\n",
      "interdisciplinary\n",
      "subfield\n",
      "of\n",
      "computer\n",
      "science\n",
      "and\n",
      "linguistics\n",
      ".\n",
      "It\n",
      "is\n",
      "primarily\n",
      "concerned\n",
      "with\n",
      "giving\n",
      "computer\n",
      "the\n",
      "ability\n",
      "to\n",
      "support\n",
      "and\n",
      "manipulate\n",
      "human\n",
      "language\n",
      ".\n",
      "It\n",
      "involves\n",
      "processing\n",
      "natural\n",
      "language\n",
      "datasets\n",
      ",\n",
      "such\n",
      "a\n",
      "text\n",
      "corpus\n",
      "or\n",
      "speech\n",
      "corpus\n",
      ",\n",
      "using\n",
      "either\n",
      "rule-based\n",
      "or\n",
      "probabilistic\n",
      "(\n",
      "i.e\n",
      ".\n",
      "statistical\n",
      "and\n",
      ",\n",
      "most\n",
      "recently\n",
      ",\n",
      "neural\n",
      "network-based\n",
      ")\n",
      "machine\n",
      "learning\n",
      "approach\n",
      ".\n",
      "The\n",
      "goal\n",
      "is\n",
      "a\n",
      "computer\n",
      "capable\n",
      "of\n",
      "understanding\n",
      "the\n",
      "content\n",
      "of\n",
      "document\n",
      ",\n",
      "including\n",
      "the\n",
      "contextual\n",
      "nuance\n",
      "of\n",
      "the\n",
      "language\n",
      "within\n",
      "them\n",
      ".\n",
      "The\n",
      "technology\n",
      "can\n",
      "then\n",
      "accurately\n",
      "extract\n",
      "information\n",
      "and\n",
      "insight\n",
      "contained\n",
      "in\n",
      "the\n",
      "document\n",
      "a\n",
      "well\n",
      "a\n",
      "categorize\n",
      "and\n",
      "organize\n",
      "the\n",
      "document\n",
      "themselves\n",
      ".\n",
      "Challenges\n",
      "in\n",
      "natural\n",
      "language\n",
      "processing\n",
      "frequently\n",
      "involve\n",
      "speech\n",
      "recognition\n",
      ",\n",
      "natural-language\n",
      "understanding\n",
      ",\n",
      "and\n",
      "natural-language\n",
      "generation\n",
      ".\n",
      "Up\n",
      "to\n",
      "the\n",
      "1980s\n",
      ",\n",
      "most\n",
      "natural\n",
      "language\n",
      "processing\n",
      "system\n",
      "were\n",
      "based\n",
      "on\n",
      "complex\n",
      "set\n",
      "of\n",
      "hand-written\n",
      "rule\n",
      ".\n",
      "Starting\n",
      "in\n",
      "the\n",
      "late\n",
      "1980s\n",
      ",\n",
      "however\n",
      ",\n",
      "there\n",
      "wa\n",
      "a\n",
      "revolution\n",
      "in\n",
      "natural\n",
      "language\n",
      "processing\n",
      "with\n",
      "the\n",
      "introduction\n",
      "of\n",
      "machine\n",
      "learning\n",
      "algorithm\n",
      "for\n",
      "language\n",
      "processing\n",
      ".\n",
      "This\n",
      "wa\n",
      "due\n",
      "to\n",
      "both\n",
      "the\n",
      "steady\n",
      "increase\n",
      "in\n",
      "computational\n",
      "power\n",
      "(\n",
      "see\n",
      "Moore\n",
      "'s\n",
      "law\n",
      ")\n",
      "and\n",
      "the\n",
      "gradual\n",
      "lessening\n",
      "of\n",
      "the\n",
      "dominance\n",
      "of\n",
      "Chomskyan\n",
      "theory\n",
      "of\n",
      "linguistics\n",
      "(\n",
      "e.g\n",
      ".\n",
      "transformational\n",
      "grammar\n",
      ")\n",
      ",\n",
      "whose\n",
      "theoretical\n",
      "underpinnings\n",
      "discouraged\n",
      "the\n",
      "sort\n",
      "of\n",
      "corpus\n",
      "linguistics\n",
      "that\n",
      "underlies\n",
      "the\n",
      "machine-learning\n",
      "approach\n",
      "to\n",
      "language\n",
      "processing\n",
      ".\n",
      "Creating\n",
      "a\n",
      "single\n",
      "sentence\n",
      "with\n",
      "50\n",
      "line\n",
      "can\n",
      "be\n",
      "quite\n",
      "challenging\n",
      "due\n",
      "to\n",
      "it\n",
      "length\n",
      "and\n",
      "complexity\n",
      ",\n",
      "but\n",
      "I\n",
      "can\n",
      "provide\n",
      "you\n",
      "with\n",
      "a\n",
      "lengthy\n",
      "sentence\n",
      "that\n",
      "attempt\n",
      "to\n",
      "cover\n",
      "a\n",
      "variety\n",
      "of\n",
      "topic\n",
      "and\n",
      "idea\n",
      ":\n",
      "It\n",
      "is\n",
      "quite\n",
      "a\n",
      "common\n",
      "requirement\n",
      "for\n",
      "user\n",
      "to\n",
      "remove\n",
      "certain\n",
      "character\n",
      "from\n",
      "their\n",
      "text\n",
      "file\n",
      "while\n",
      "displaying\n",
      ".\n",
      "This\n",
      "is\n",
      "done\n",
      "to\n",
      "assure\n",
      "that\n",
      "only\n",
      "displayable\n",
      "character\n",
      "are\n",
      "displayed\n",
      "or\n",
      "data\n",
      "should\n",
      "be\n",
      "displayed\n",
      "in\n",
      "a\n",
      "specific\n",
      "structure\n",
      ".\n",
      "This\n",
      "article\n",
      "will\n",
      "teach\n",
      "you\n",
      "how\n",
      "to\n",
      "read\n",
      "a\n",
      "text\n",
      "file\n",
      "into\n",
      "a\n",
      "string\n",
      "variable\n",
      "and\n",
      "strip\n",
      "newlines\n",
      "using\n",
      "Python\n",
      ".\n",
      "The\n",
      "task\n",
      "could\n",
      "be\n",
      "performed\n",
      "using\n",
      "the\n",
      "replace\n",
      "function\n",
      ",\n",
      "a\n",
      "default\n",
      "function\n",
      "in\n",
      "all\n",
      "Python\n",
      "distribution\n",
      ".\n",
      "Where\n",
      "old\n",
      "is\n",
      "the\n",
      "string\n",
      "to\n",
      "be\n",
      "replaced\n",
      "and\n",
      "new\n",
      "is\n",
      "the\n",
      "string\n",
      "that\n",
      "will\n",
      "replace\n",
      "it\n",
      ".\n",
      "Firstly\n",
      "the\n",
      "path\n",
      "to\n",
      "the\n",
      "file\n",
      "is\n",
      "defined\n",
      ".\n",
      "Then\n",
      "the\n",
      "fileâ€™s\n",
      "content\n",
      "are\n",
      "read\n",
      "and\n",
      "stored\n",
      "in\n",
      "the\n",
      "variable\n",
      "named\n",
      "data\n",
      ".\n",
      "All\n",
      "the\n",
      "occurrence\n",
      "of\n",
      "the\n",
      "newline\n",
      "character\n",
      "in\n",
      "the\n",
      "variable\n",
      "data\n",
      "are\n",
      "replaced\n",
      "with\n",
      "the\n",
      "empty\n",
      "string\n",
      "(\n",
      "nothing\n",
      ")\n",
      ".\n",
      "In\n",
      "the\n",
      "end\n",
      ",\n",
      "the\n",
      "data\n",
      "after\n",
      "stripping\n",
      "the\n",
      "newlines\n",
      "are\n",
      "displayed\n",
      ".\n",
      "The\n",
      "task\n",
      "could\n",
      "also\n",
      "be\n",
      "performed\n",
      "using\n",
      "the\n",
      "split\n",
      "function\n",
      ",\n",
      "a\n",
      "default\n",
      "function\n",
      "in\n",
      "all\n",
      "Python\n",
      "distribution\n",
      ".\n",
      "The\n",
      "function\n",
      "take\n",
      "in\n",
      "an\n",
      "argument\n",
      "(\n",
      "optional\n",
      ")\n",
      "a\n",
      "character\n",
      "(\n",
      "or\n",
      "string\n",
      ")\n",
      "and\n",
      "split\n",
      "the\n",
      "string\n",
      "based\n",
      "on\n",
      "the\n",
      "occurrence\n",
      "of\n",
      "that\n",
      "character\n",
      "in\n",
      "it\n",
      ".\n",
      "Firstly\n",
      "the\n",
      "file\n",
      "is\n",
      "read\n",
      "and\n",
      "stored\n",
      "in\n",
      "a\n",
      "variable\n",
      "a\n",
      "before\n",
      ".\n",
      "Then\n",
      "the\n",
      "variable\n",
      "is\n",
      "passed\n",
      "through\n",
      "the\n",
      "split\n",
      "function\n",
      ",\n",
      "which\n",
      "split\n",
      "the\n",
      "string\n",
      "and\n",
      "creates\n",
      "a\n",
      "list\n",
      "based\n",
      "on\n",
      "the\n",
      "occurrence\n",
      "of\n",
      "the\n",
      "passed\n",
      "argument\n",
      ".\n",
      "In\n",
      "this\n",
      "case\n",
      ",\n",
      "it\n",
      "wa\n",
      "the\n",
      "newline\n",
      "character\n",
      ".\n",
      "Thus\n",
      "after\n",
      "this\n",
      "process\n",
      ",\n",
      "we\n",
      "ended\n",
      "up\n",
      "with\n",
      "a\n",
      "list\n",
      "containing\n",
      "substring\n",
      "of\n",
      "the\n",
      "original\n",
      "string\n",
      ".\n",
      "The\n",
      "Splitlines\n",
      "is\n",
      "a\n",
      "function\n",
      "that\n",
      "splits/breaks\n",
      "a\n",
      "string\n",
      "based\n",
      "on\n",
      "the\n",
      "occurrence\n",
      "of\n",
      "escape\n",
      "sequence\n",
      ".\n",
      "The\n",
      "function\n",
      "convert\n",
      "the\n",
      "string\n",
      "to\n",
      "a\n",
      "list\n",
      "upon\n",
      "stripping\n",
      "the\n",
      "control\n",
      "character\n",
      ".\n",
      "Hence\n",
      ",\n",
      "all\n",
      "the\n",
      "list\n",
      "element\n",
      "must\n",
      "be\n",
      "iterated\n",
      "to\n",
      "get\n",
      "the\n",
      "final\n",
      "string\n",
      ".\n",
      "This\n",
      "method\n",
      "is\n",
      "almost\n",
      "identical\n",
      "to\n",
      "the\n",
      "split\n",
      "method\n",
      "described\n",
      "earlier\n",
      ".\n",
      "The\n",
      "only\n",
      "difference\n",
      "is\n",
      "that\n",
      "the\n",
      "split\n",
      "line\n",
      "function\n",
      "doe\n",
      "not\n",
      "require\n",
      "any\n",
      "argument\n",
      "and\n",
      "is\n",
      "made\n",
      "to\n",
      "work\n",
      "only\n",
      "with\n",
      "line\n",
      "boundary\n",
      ".\n",
      "Hence\n",
      ",\n",
      "the\n",
      "splitting\n",
      "of\n",
      "data\n",
      "would\n",
      "be\n",
      "made\n",
      "on\n",
      "any\n",
      "occurrence\n",
      "of\n",
      "a\n",
      "line\n",
      "boundary\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "#lemmatization\n",
    "\n",
    "lemma1 = WordNetLemmatizer()\n",
    "\n",
    "for i in token1:\n",
    "    print(lemma1.lemmatize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqMBelvPiyOd",
    "outputId": "96480818-2435-4241-8e3f-0791857e64e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('an', 'DT'), ('interdisciplinary', 'JJ'), ('subfield', 'NN'), ('of', 'IN'), ('computer', 'NN'), ('science', 'NN'), ('and', 'CC'), ('linguistics', 'NNS'), ('.', '.')]\n",
      "[('It', 'PRP'), ('is', 'VBZ'), ('primarily', 'RB'), ('concerned', 'VBN'), ('with', 'IN'), ('giving', 'VBG'), ('computers', 'NNS'), ('the', 'DT'), ('ability', 'NN'), ('to', 'TO'), ('support', 'VB'), ('and', 'CC'), ('manipulate', 'VB'), ('human', 'JJ'), ('language', 'NN'), ('.', '.')]\n",
      "[('It', 'PRP'), ('involves', 'VBZ'), ('processing', 'VBG'), ('natural', 'JJ'), ('language', 'NN'), ('datasets', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('text', 'JJ'), ('corpora', 'NN'), ('or', 'CC'), ('speech', 'NN'), ('corpora', 'NNS'), (',', ','), ('using', 'VBG'), ('either', 'CC'), ('rule-based', 'JJ'), ('or', 'CC'), ('probabilistic', 'JJ'), ('(', '('), ('i.e', 'NN'), ('.', '.')]\n",
      "[('statistical', 'JJ'), ('and', 'CC'), (',', ','), ('most', 'RBS'), ('recently', 'RB'), (',', ','), ('neural', 'JJ'), ('network-based', 'JJ'), (')', ')'), ('machine', 'NN'), ('learning', 'VBG'), ('approaches', 'NNS'), ('.', '.')]\n",
      "[('The', 'DT'), ('goal', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('computer', 'NN'), ('capable', 'NN'), ('of', 'IN'), ('understanding', 'VBG'), ('the', 'DT'), ('contents', 'NNS'), ('of', 'IN'), ('documents', 'NNS'), (',', ','), ('including', 'VBG'), ('the', 'DT'), ('contextual', 'JJ'), ('nuances', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('language', 'NN'), ('within', 'IN'), ('them', 'PRP'), ('.', '.')]\n",
      "[('The', 'DT'), ('technology', 'NN'), ('can', 'MD'), ('then', 'RB'), ('accurately', 'RB'), ('extract', 'JJ'), ('information', 'NN'), ('and', 'CC'), ('insights', 'NNS'), ('contained', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('documents', 'NNS'), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('categorize', 'NN'), ('and', 'CC'), ('organize', 'VB'), ('the', 'DT'), ('documents', 'NNS'), ('themselves', 'PRP'), ('.', '.')]\n",
      "[('Challenges', 'NNS'), ('in', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('frequently', 'RB'), ('involve', 'VBP'), ('speech', 'NN'), ('recognition', 'NN'), (',', ','), ('natural-language', 'JJ'), ('understanding', 'NN'), (',', ','), ('and', 'CC'), ('natural-language', 'JJ'), ('generation', 'NN'), ('.', '.')]\n",
      "[('Up', 'RB'), ('to', 'TO'), ('the', 'DT'), ('1980s', 'CD'), (',', ','), ('most', 'RBS'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'VBG'), ('systems', 'NNS'), ('were', 'VBD'), ('based', 'VBN'), ('on', 'IN'), ('complex', 'JJ'), ('sets', 'NNS'), ('of', 'IN'), ('hand-written', 'JJ'), ('rules', 'NNS'), ('.', '.')]\n",
      "[('Starting', 'VBG'), ('in', 'IN'), ('the', 'DT'), ('late', 'JJ'), ('1980s', 'NNS'), (',', ','), ('however', 'RB'), (',', ','), ('there', 'EX'), ('was', 'VBD'), ('a', 'DT'), ('revolution', 'NN'), ('in', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('with', 'IN'), ('the', 'DT'), ('introduction', 'NN'), ('of', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('algorithms', 'NN'), ('for', 'IN'), ('language', 'NN'), ('processing', 'NN'), ('.', '.')]\n",
      "[('This', 'DT'), ('was', 'VBD'), ('due', 'JJ'), ('to', 'TO'), ('both', 'DT'), ('the', 'DT'), ('steady', 'JJ'), ('increase', 'NN'), ('in', 'IN'), ('computational', 'JJ'), ('power', 'NN'), ('(', '('), ('see', 'VB'), ('Moore', 'NNP'), (\"'s\", 'POS'), ('law', 'NN'), (')', ')'), ('and', 'CC'), ('the', 'DT'), ('gradual', 'JJ'), ('lessening', 'NN'), ('of', 'IN'), ('the', 'DT'), ('dominance', 'NN'), ('of', 'IN'), ('Chomskyan', 'NNP'), ('theories', 'NNS'), ('of', 'IN'), ('linguistics', 'NNS'), ('(', '('), ('e.g', 'NN'), ('.', '.')]\n",
      "[('transformational', 'JJ'), ('grammar', 'NN'), (')', ')'), (',', ','), ('whose', 'WP$'), ('theoretical', 'JJ'), ('underpinnings', 'NNS'), ('discouraged', 'VBD'), ('the', 'DT'), ('sort', 'NN'), ('of', 'IN'), ('corpus', 'NN'), ('linguistics', 'NNS'), ('that', 'WDT'), ('underlies', 'VBZ'), ('the', 'DT'), ('machine-learning', 'JJ'), ('approach', 'NN'), ('to', 'TO'), ('language', 'NN'), ('processing', 'NN'), ('.', '.')]\n",
      "[('Creating', 'VBG'), ('a', 'DT'), ('single', 'JJ'), ('sentence', 'NN'), ('with', 'IN'), ('50', 'CD'), ('lines', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('quite', 'RB'), ('challenging', 'VBG'), ('due', 'JJ'), ('to', 'TO'), ('its', 'PRP$'), ('length', 'NN'), ('and', 'CC'), ('complexity', 'NN'), (',', ','), ('but', 'CC'), ('I', 'PRP'), ('can', 'MD'), ('provide', 'VB'), ('you', 'PRP'), ('with', 'IN'), ('a', 'DT'), ('lengthy', 'JJ'), ('sentence', 'NN'), ('that', 'WDT'), ('attempts', 'VBZ'), ('to', 'TO'), ('cover', 'VB'), ('a', 'DT'), ('variety', 'NN'), ('of', 'IN'), ('topics', 'NNS'), ('and', 'CC'), ('ideas', 'NNS'), (':', ':'), ('It', 'PRP'), ('is', 'VBZ'), ('quite', 'RB'), ('a', 'DT'), ('common', 'JJ'), ('requirement', 'NN'), ('for', 'IN'), ('users', 'NNS'), ('to', 'TO'), ('remove', 'VB'), ('certain', 'JJ'), ('characters', 'NNS'), ('from', 'IN'), ('their', 'PRP$'), ('text', 'NN'), ('files', 'NNS'), ('while', 'IN'), ('displaying', 'VBG'), ('.', '.')]\n",
      "[('This', 'DT'), ('is', 'VBZ'), ('done', 'VBN'), ('to', 'TO'), ('assure', 'VB'), ('that', 'IN'), ('only', 'RB'), ('displayable', 'JJ'), ('characters', 'NNS'), ('are', 'VBP'), ('displayed', 'VBN'), ('or', 'CC'), ('data', 'NNS'), ('should', 'MD'), ('be', 'VB'), ('displayed', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('specific', 'JJ'), ('structure', 'NN'), ('.', '.')]\n",
      "[('This', 'DT'), ('article', 'NN'), ('will', 'MD'), ('teach', 'VB'), ('you', 'PRP'), ('how', 'WRB'), ('to', 'TO'), ('read', 'VB'), ('a', 'DT'), ('text', 'NN'), ('file', 'NN'), ('into', 'IN'), ('a', 'DT'), ('string', 'NN'), ('variable', 'JJ'), ('and', 'CC'), ('strip', 'JJ'), ('newlines', 'NNS'), ('using', 'VBG'), ('Python', 'NNP'), ('.', '.')]\n",
      "[('The', 'DT'), ('task', 'NN'), ('could', 'MD'), ('be', 'VB'), ('performed', 'VBN'), ('using', 'VBG'), ('the', 'DT'), ('replace', 'VB'), ('function', 'NN'), (',', ','), ('a', 'DT'), ('default', 'NN'), ('function', 'NN'), ('in', 'IN'), ('all', 'DT'), ('Python', 'NNP'), ('distributions', 'NNS'), ('.', '.')]\n",
      "[('Where', 'WRB'), ('old', 'JJ'), ('is', 'VBZ'), ('the', 'DT'), ('string', 'NN'), ('to', 'TO'), ('be', 'VB'), ('replaced', 'VBN'), ('and', 'CC'), ('new', 'JJ'), ('is', 'VBZ'), ('the', 'DT'), ('string', 'NN'), ('that', 'WDT'), ('will', 'MD'), ('replace', 'VB'), ('it', 'PRP'), ('.', '.')]\n",
      "[('Firstly', 'RB'), ('the', 'DT'), ('path', 'NN'), ('to', 'TO'), ('the', 'DT'), ('file', 'NN'), ('is', 'VBZ'), ('defined', 'VBN'), ('.', '.')]\n",
      "[('Then', 'RB'), ('the', 'DT'), ('fileâ€™s', 'NN'), ('contents', 'NNS'), ('are', 'VBP'), ('read', 'VBN'), ('and', 'CC'), ('stored', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('variable', 'NN'), ('named', 'VBN'), ('data', 'NNS'), ('.', '.')]\n",
      "[('All', 'PDT'), ('the', 'DT'), ('occurrences', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('newline', 'JJ'), ('character', 'NN'), ('in', 'IN'), ('the', 'DT'), ('variable', 'JJ'), ('data', 'NNS'), ('are', 'VBP'), ('replaced', 'VBN'), ('with', 'IN'), ('the', 'DT'), ('empty', 'JJ'), ('string', 'NN'), ('(', '('), ('nothing', 'NN'), (')', ')'), ('.', '.')]\n",
      "[('In', 'IN'), ('the', 'DT'), ('end', 'NN'), (',', ','), ('the', 'DT'), ('data', 'NNS'), ('after', 'IN'), ('stripping', 'VBG'), ('the', 'DT'), ('newlines', 'NNS'), ('are', 'VBP'), ('displayed', 'VBN'), ('.', '.')]\n",
      "[('The', 'DT'), ('task', 'NN'), ('could', 'MD'), ('also', 'RB'), ('be', 'VB'), ('performed', 'VBN'), ('using', 'VBG'), ('the', 'DT'), ('split', 'NN'), ('function', 'NN'), (',', ','), ('a', 'DT'), ('default', 'NN'), ('function', 'NN'), ('in', 'IN'), ('all', 'DT'), ('Python', 'NNP'), ('distributions', 'NNS'), ('.', '.')]\n",
      "[('The', 'DT'), ('function', 'NN'), ('takes', 'VBZ'), ('in', 'IN'), ('an', 'DT'), ('argument', 'NN'), ('(', '('), ('optional', 'JJ'), (')', ')'), ('a', 'DT'), ('character', 'NN'), ('(', '('), ('or', 'CC'), ('string', 'VBG'), (')', ')'), ('and', 'CC'), ('splits', 'VBZ'), ('the', 'DT'), ('string', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('occurrence', 'NN'), ('of', 'IN'), ('that', 'DT'), ('character', 'NN'), ('in', 'IN'), ('it', 'PRP'), ('.', '.')]\n",
      "[('Firstly', 'RB'), ('the', 'DT'), ('file', 'NN'), ('is', 'VBZ'), ('read', 'VBN'), ('and', 'CC'), ('stored', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('variable', 'JJ'), ('as', 'IN'), ('before', 'RB'), ('.', '.')]\n",
      "[('Then', 'RB'), ('the', 'DT'), ('variable', 'NN'), ('is', 'VBZ'), ('passed', 'VBN'), ('through', 'IN'), ('the', 'DT'), ('split', 'NN'), ('function', 'NN'), (',', ','), ('which', 'WDT'), ('splits', 'VBZ'), ('the', 'DT'), ('string', 'NN'), ('and', 'CC'), ('creates', 'VBZ'), ('a', 'DT'), ('list', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('occurrences', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('passed', 'VBN'), ('argument', 'NN'), ('.', '.')]\n",
      "[('In', 'IN'), ('this', 'DT'), ('case', 'NN'), (',', ','), ('it', 'PRP'), ('was', 'VBD'), ('the', 'DT'), ('newline', 'JJ'), ('character', 'NN'), ('.', '.')]\n",
      "[('Thus', 'RB'), ('after', 'IN'), ('this', 'DT'), ('process', 'NN'), (',', ','), ('we', 'PRP'), ('ended', 'VBD'), ('up', 'RP'), ('with', 'IN'), ('a', 'DT'), ('list', 'NN'), ('containing', 'VBG'), ('substrings', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('strings', 'NNS'), ('.', '.')]\n",
      "[('The', 'DT'), ('Splitlines', 'NNPS'), ('is', 'VBZ'), ('a', 'DT'), ('function', 'NN'), ('that', 'WDT'), ('splits/breaks', 'VBZ'), ('a', 'DT'), ('string', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('occurrence', 'NN'), ('of', 'IN'), ('escape', 'NN'), ('sequences', 'NNS'), ('.', '.')]\n",
      "[('The', 'DT'), ('function', 'NN'), ('converts', 'VBZ'), ('the', 'DT'), ('string', 'NN'), ('to', 'TO'), ('a', 'DT'), ('list', 'NN'), ('upon', 'IN'), ('stripping', 'VBG'), ('the', 'DT'), ('control', 'NN'), ('characters', 'NNS'), ('.', '.')]\n",
      "[('Hence', 'NNP'), (',', ','), ('all', 'PDT'), ('the', 'DT'), ('list', 'NN'), ('elements', 'NNS'), ('must', 'MD'), ('be', 'VB'), ('iterated', 'VBN'), ('to', 'TO'), ('get', 'VB'), ('the', 'DT'), ('final', 'JJ'), ('string', 'NN'), ('.', '.')]\n",
      "[('This', 'DT'), ('method', 'NN'), ('is', 'VBZ'), ('almost', 'RB'), ('identical', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('split', 'NN'), ('method', 'NN'), ('described', 'VBN'), ('earlier', 'RBR'), ('.', '.')]\n",
      "[('The', 'DT'), ('only', 'JJ'), ('difference', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('the', 'DT'), ('split', 'NN'), ('lines', 'NNS'), ('function', 'NN'), ('does', 'VBZ'), ('not', 'RB'), ('require', 'VB'), ('any', 'DT'), ('argument', 'NN'), ('and', 'CC'), ('is', 'VBZ'), ('made', 'VBN'), ('to', 'TO'), ('work', 'VB'), ('only', 'RB'), ('with', 'IN'), ('line', 'NN'), ('boundaries', 'NNS'), ('.', '.')]\n",
      "[('Hence', 'NNP'), (',', ','), ('the', 'DT'), ('splitting', 'NN'), ('of', 'IN'), ('data', 'NNS'), ('would', 'MD'), ('be', 'VB'), ('made', 'VBN'), ('on', 'IN'), ('any', 'DT'), ('occurrence', 'NN'), ('of', 'IN'), ('a', 'DT'), ('line', 'NN'), ('boundary', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#Pos_tagging\n",
    "\n",
    "for i in token2:\n",
    "  print(nltk.pos_tag(wt(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJ4EEGhpi5AP",
    "outputId": "61324ea8-8c9a-4501-d669-0d7768e76b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "set1 = stopwords.words('english')\n",
    "print(set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pxhY6Fxi76Q",
    "outputId": "2fc30e48-db4b-417e-925d-a3f9092abe46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'an', 'interdisciplinary', 'subfield', 'computer', 'science', 'linguistics', '.', 'It', 'primarily', 'concerned', 'giving', 'computers', 'ability', 'support', 'manipulate', 'human', 'language', '.', 'It', 'involves', 'processing', 'natural', 'language', 'datasets', ',', 'text', 'corpora', 'speech', 'corpora', ',', 'using', 'either', 'rule-based', 'probabilistic', '(', 'i.e', '.', 'statistical', ',', 'recently', ',', 'neural', 'network-based', ')', 'machine', 'learning', 'approaches', '.', 'The', 'goal', 'computer', 'capable', 'understanding', 'contents', 'documents', ',', 'including', 'contextual', 'nuances', 'language', 'within', '.', 'The', 'technology', 'then', 'accurately', 'extract', 'information', 'insights', 'contained', 'documents', 'well', 'categorize', 'organize', 'documents', '.', 'Challenges', 'natural', 'language', 'processing', 'frequently', 'involve', 'speech', 'recognition', ',', 'natural-language', 'understanding', ',', 'natural-language', 'generation', '.', 'Up', '1980s', ',', 'natural', 'language', 'processing', 'systems', 'based', 'complex', 'sets', 'hand-written', 'rules', '.', 'Starting', 'late', '1980s', ',', 'however', ',', 'revolution', 'natural', 'language', 'processing', 'introduction', 'machine', 'learning', 'algorithms', 'language', 'processing', '.', 'This', 'was', 'due', 'both', 'steady', 'increase', 'computational', 'power', '(', 'see', 'Moore', \"'s\", 'law', ')', 'gradual', 'lessening', 'dominance', 'Chomskyan', 'theories', 'linguistics', '(', 'e.g', '.', 'transformational', 'grammar', ')', ',', 'whose', 'theoretical', 'underpinnings', 'discouraged', 'sort', 'corpus', 'linguistics', 'underlies', 'machine-learning', 'approach', 'language', 'processing', '.', 'Creating', 'single', 'sentence', '50', 'lines', 'quite', 'challenging', 'due', 'its', 'length', 'complexity', ',', 'I', 'provide', 'lengthy', 'sentence', 'attempts', 'cover', 'variety', 'topics', 'ideas', ':', 'It', 'quite', 'common', 'requirement', 'users', 'remove', 'certain', 'characters', 'their', 'text', 'files', 'displaying', '.', 'This', 'done', 'assure', 'displayable', 'characters', 'displayed', 'data', 'displayed', 'specific', 'structure', '.', 'This', 'article', 'teach', 'how', 'read', 'text', 'file', 'string', 'variable', 'strip', 'newlines', 'using', 'Python', '.', 'The', 'task', 'could', 'performed', 'using', 'replace', 'function', ',', 'default', 'function', 'Python', 'distributions', '.', 'Where', 'old', 'string', 'replaced', 'new', 'string', 'will', 'replace', '.', 'Firstly', 'path', 'file', 'defined', '.', 'Then', 'fileâ€™s', 'contents', 'read', 'stored', 'variable', 'named', 'data', '.', 'All', 'occurrences', 'newline', 'character', 'variable', 'data', 'replaced', 'with', 'empty', 'string', '(', 'nothing', ')', '.', 'In', 'the', 'end', ',', 'the', 'data', 'stripping', 'the', 'newlines', 'displayed', '.', 'The', 'task', 'could', 'also', 'be', 'performed', 'using', 'the', 'split', 'function', ',', 'default', 'function', 'all', 'Python', 'distributions', '.', 'The', 'function', 'takes', 'an', 'argument', '(', 'optional', ')', 'character', '(', 'string', ')', 'splits', 'the', 'string', 'based', 'the', 'occurrence', 'character', '.', 'Firstly', 'the', 'file', 'read', 'stored', 'a', 'variable', 'as', 'before', '.', 'Then', 'the', 'variable', 'passed', 'the', 'split', 'function', ',', 'splits', 'the', 'string', 'creates', 'a', 'list', 'based', 'the', 'occurrences', 'the', 'passed', 'argument', '.', 'In', 'case', ',', 'it', 'was', 'the', 'newline', 'character', '.', 'Thus', 'this', 'process', ',', 'ended', 'with', 'a', 'list', 'containing', 'substrings', 'the', 'original', 'strings', '.', 'The', 'Splitlines', 'a', 'function', 'that', 'splits/breaks', 'a', 'string', 'based', 'the', 'occurrence', 'escape', 'sequences', '.', 'The', 'function', 'converts', 'the', 'string', 'a', 'list', 'upon', 'stripping', 'the', 'control', 'characters', '.', 'Hence', ',', 'all', 'the', 'list', 'elements', 'must', 'be', 'iterated', 'get', 'the', 'final', 'string', '.', 'This', 'method', 'almost', 'identical', 'the', 'split', 'method', 'described', 'earlier', '.', 'The', 'difference', 'that', 'the', 'split', 'lines', 'function', 'not', 'require', 'argument', 'is', 'made', 'work', 'only', 'with', 'line', 'boundaries', '.', 'Hence', ',', 'the', 'splitting', 'data', 'would', 'be', 'made', 'any', 'occurrence', 'a', 'line', 'boundary', '.']\n"
     ]
    }
   ],
   "source": [
    "for i in token1:\n",
    "  if(i in set1):\n",
    "    token1.remove(i)\n",
    "\n",
    "print(token1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
